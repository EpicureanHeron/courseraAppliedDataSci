{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/25/93 Total time of visit (in minutes):\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/18/85 Primary Care Doctor:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sshe plans to move as of 7/8/71 In-Home Servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7 on 9/27/75 Audit C Score Current:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/6/96 sleep studyPain Treatment Pain Level (N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.Per 7/06/79 Movement D/O note:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4, 5/18/78 Patient's thoughts about current su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/24/89 CPT Code: 90801 - Psychiatric Diagnos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/7/86 SOS-10 Total Score:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(4/10/71)Score-1Audit C Score Current:\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0       03/25/93 Total time of visit (in minutes):\\n\n",
       "1                     6/18/85 Primary Care Doctor:\\n\n",
       "2  sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3              7 on 9/27/75 Audit C Score Current:\\n\n",
       "4  2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "5                  .Per 7/06/79 Movement D/O note:\\n\n",
       "6  4, 5/18/78 Patient's thoughts about current su...\n",
       "7  10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
       "8                       3/7/86 SOS-10 Total Score:\\n\n",
       "9           (4/10/71)Score-1Audit C Score Current:\\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.DataFrame(doc, columns=['text'])\n",
    "# df.head(10)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:180: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2       53\n",
       "3        2\n",
       "4       28\n",
       "5      474\n",
       "6      153\n",
       "7      129\n",
       "8      225\n",
       "9      171\n",
       "10     191\n",
       "11      13\n",
       "12      98\n",
       "13     111\n",
       "14      31\n",
       "15     486\n",
       "16     335\n",
       "17     323\n",
       "18     345\n",
       "19     405\n",
       "20      57\n",
       "21     415\n",
       "22      36\n",
       "23     422\n",
       "24     375\n",
       "25     380\n",
       "26     481\n",
       "27     299\n",
       "28     162\n",
       "29     154\n",
       "      ... \n",
       "470    208\n",
       "471    139\n",
       "472    320\n",
       "473    383\n",
       "474    393\n",
       "475     34\n",
       "476    244\n",
       "477    286\n",
       "478    480\n",
       "479    279\n",
       "480    198\n",
       "481    431\n",
       "482    463\n",
       "483    255\n",
       "484    381\n",
       "485    439\n",
       "486    401\n",
       "487    366\n",
       "488    475\n",
       "489    257\n",
       "490    152\n",
       "491    235\n",
       "492    464\n",
       "493    253\n",
       "494    231\n",
       "495    141\n",
       "496    186\n",
       "497    161\n",
       "498    413\n",
       "499    427\n",
       "Name: index, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def date_sorter():\n",
    "    \n",
    "    doc = []\n",
    "    with open('dates.txt') as file:\n",
    "        for line in file:\n",
    "            doc.append(line)\n",
    " \n",
    "            \n",
    "#     current plan as of 10/26\n",
    "# INITIAL PROCESSING\n",
    "#  map out each iteration of the regex to a unique dataframe with the OriginalMatch, Month, Day, Year\n",
    "# DATA PROCESSING\n",
    "# drop any np.nan amounts from those dfs where it makes sense EG if only grabbing the year...should probably key off of the year column as there will be a lot of false positives if matching based on days and month\n",
    "# add the data for any of those that are missing data and potentially do a conversion if need be for a key value of SEPT = 9, OCT=10 etc\n",
    "# combine all values based on columns and create a new data frame with real pandas datetime objects\n",
    "\n",
    "# SORT!\n",
    "       \n",
    "\n",
    "# done 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "# done grouping see iloc[1]\n",
    "    pattern1 = '(?P<OriginalMatch>(?P<Month>\\d?\\d)[/|-](?P<Day>\\d?\\d)[/|-](?P<Year>\\d{2,4}))'\n",
    "    \n",
    "    \n",
    "# Mar-20-2009; Mar 20, 2009; March 20, 2009; Mar. 20, 2009; Mar 20 2009;\n",
    "# couldn't find any wild examples, copied and apsted the above and validated\n",
    "    pattern2 =  '(?P<OriginalMatch>(?P<Month>(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))[\\S]*[^a-zA-Z\\d:](?P<Day>\\d{1,2})[\\S]*[^a-zA-Z\\d:](?P<Year>\\d{4}))'  \n",
    "\n",
    "    \n",
    "    \n",
    "# done 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "#  done grouping see iloc[150]\n",
    "    pattern3 = '(?P<OriginalMatch>(?P<Day>\\d{1,2})[+\\s|-](?P<Month>(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))[\\S]*[\\s|-](?P<Year>\\d{4}))'\n",
    "\n",
    "    # done Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "#     cannot find any \"in the wild\" examples but added the above and it is grouping correctly\n",
    "# tested and done grouping\n",
    "    pattern4 = '(?P<OriginalMatch>(?P<Month>(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))[\\S]*[\\s](?P<Day>\\d{1,2})[\\S]*[,][\\s](?P<Year>\\d{4}))'\n",
    "\n",
    "    # done  grouping Feb 2009; Sep 2009; Oct 2010\n",
    "# breakdown for pattern 5\n",
    "# [^\\d{1,2}] the first group does not match 1 to two digits\n",
    "# [+\\s|-] matches whitespace (note different than the ^ on the first block, which is a DOES NOT MATCH) aOR it matches a hyphen\n",
    "# (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) then it is grabbing the group (the [parenthesis] ) which matches any of the variations on monhts\n",
    "# [\\S]*[\\s] is not grabbing (hence the brackets) any string characters (eg a-zA-Z) so January. followed by white space But it is not including those in the grouping\n",
    "# (\\d{4} then it is grabbing the 4 digit year\n",
    "# done \n",
    "# lookup 258\n",
    "# done grouping\n",
    "    pattern5 = '(?P<OriginalMatch>[^\\d{1,2}]?\\S?(?P<Month>(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))[\\S]*[\\s|-](?P<Year>\\d{4}))'\n",
    "   \n",
    "\n",
    "    # done  6/2008; 12/2009\n",
    "    # iloc[453] \n",
    "#     done grouping\n",
    "    pattern6 = '(?P<OriginalMatch>[\\s|^/|\\~|\\.|\\(|\\|)|\\d/]?(?P<Month>\\d{1,2})/(?P<Year>\\d{4}))'\n",
    "\n",
    "# done 2009; 2010\n",
    "# works for lookup 457, middle of the line\n",
    "# works for lookup 477, beginning of the line  \n",
    "# does not match look up 445, 7/1981\n",
    "# this works pretty well...but I don't want to code EVERYTHING with this...it is hungry so APR 2010 would be captured.\n",
    "# so maybe run pattern7 on the remaining dataframe after removing anything that matched before\n",
    "    pattern7 = '(?P<OriginalMatch>(?<!/)[^/|\\s|\\~|\\.|\\(|\\|)]?(?P<Year>[1|2]\\d{3})(?!\\d{1,2}/))'\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(doc, columns=['text'])\n",
    "    \n",
    "    month_dictionary = {\n",
    "        'Jan': 1,\n",
    "        'Feb': 2,\n",
    "        'Mar': 3,\n",
    "        'Apr': 4,\n",
    "        'May': 5,\n",
    "        'Jun': 6,\n",
    "        'Jul': 7,\n",
    "        'Aug': 8,\n",
    "        'Sep': 9,\n",
    "        'Oct': 10,\n",
    "        'Nov': 11,\n",
    "        'Dec': 12\n",
    "    }\n",
    "    \n",
    "#     PATTERN 1 PROCESSING\n",
    "# \n",
    "    \n",
    "    df_pattern1 = df['text'].str.extract(pattern1)\n",
    "    \n",
    "    df_pattern1 = df_pattern1.dropna()\n",
    "    \n",
    "    pattern1_indexes = df_pattern1.index.values.tolist()\n",
    "\n",
    "#     some year dates are only two digits, so check their length, and if they are two digits, change them into a string and add a '19' to the front, per the assignment's instructions\n",
    "    df_pattern1[\"Year\"] = df_pattern1['Year'].apply(lambda x: '19'+str(x) if len(x) == 2 else x)\n",
    "#     need to convert the year back to a number at some point. Oh Well.\n",
    "#     df_pattern1 = df_pattern1.to_numeric\n",
    "    \n",
    "    df = df.drop(pattern1_indexes) \n",
    "    \n",
    "#     PATTERN 2 PROCESSING\n",
    "    \n",
    "    df_pattern2 = df['text'].str.extract(pattern2)\n",
    "    \n",
    "    df_pattern2 = df_pattern2.dropna()\n",
    "    \n",
    "    df_pattern2_indexes = df_pattern2.index.values.tolist()\n",
    "    \n",
    "    df_pattern2[\"Month\"] = df_pattern2['Month'].apply(lambda x: month_dictionary[x])\n",
    "    \n",
    "    df = df.drop(df_pattern2_indexes) \n",
    "    \n",
    "#     PATTERN 3 PROCESSING\n",
    "\n",
    "    df_pattern3 = df['text'].str.extract(pattern3)\n",
    "    \n",
    "    df_pattern3 = df_pattern3.dropna()\n",
    "    \n",
    "    df_pattern3[\"Month\"] = df_pattern3['Month'].apply(lambda x: month_dictionary[x])\n",
    "    \n",
    "    df_pattern3_indexes = df_pattern3.index.values.tolist()\n",
    "    \n",
    "    df = df.drop(df_pattern3_indexes) \n",
    "    \n",
    "# PATTERN 4 (nothing in this one)\n",
    "\n",
    "    df_pattern4 = df['text'].str.extract(pattern4)\n",
    "    \n",
    "    df_pattern4 = df_pattern4.dropna()\n",
    "    \n",
    "    df_pattern4_indexes = df_pattern4.index.values.tolist()\n",
    "    \n",
    "    df = df.drop(df_pattern4_indexes) \n",
    "\n",
    "# PATTERN 5\n",
    "    df_pattern5 = df['text'].str.extract(pattern5)\n",
    "    \n",
    "    df_pattern5 = df_pattern5.dropna()\n",
    "    \n",
    "    df_pattern5[\"Month\"] = df_pattern5['Month'].apply(lambda x: month_dictionary[x])\n",
    "    \n",
    "#     this pattern doesn't have a day value, so a 1 is hardcoded in the day column\n",
    "\n",
    "    df_pattern5['Day']  = 1\n",
    "    \n",
    "    df_pattern5_indexes = df_pattern5.index.values.tolist()\n",
    "    \n",
    "    df = df.drop(df_pattern5_indexes) \n",
    "# PATTERN 6\n",
    "    df_pattern6 = df['text'].str.extract(pattern6)\n",
    "    \n",
    "    df_pattern6 = df_pattern6.dropna()\n",
    "    \n",
    "    df_pattern6['Day']  = 1\n",
    "    \n",
    "    df_pattern6_indexes = df_pattern6.index.values.tolist()\n",
    "    \n",
    "    df = df.drop(df_pattern6_indexes) \n",
    "# PATTERN 7\n",
    "    df_pattern7 = df['text'].str.extract(pattern7)\n",
    "    \n",
    "    df_pattern7 = df_pattern7.dropna()\n",
    "    \n",
    "    df_pattern7['Day']  = 1\n",
    "    \n",
    "    df_pattern7['Month']  = 1\n",
    "    \n",
    "    df_pattern7_indexes = df_pattern7.index.values.tolist()\n",
    "    \n",
    "    df = df.drop(df_pattern7_indexes) \n",
    "    \n",
    "    \n",
    "    normalized_df = pd.concat([df_pattern1, df_pattern2, df_pattern3, df_pattern4,\n",
    "                               df_pattern5, df_pattern6, df_pattern7], ignore_index=False, sort=True)\n",
    "    \n",
    "    sorted_df = normalized_df.sort_values(by=['Year', 'Month', 'Day'])\n",
    "    \n",
    "    sorted_df = sorted_df.reset_index()\n",
    "    \n",
    "    s = sorted_df.ix[:,0]\n",
    "    \n",
    "    return s\n",
    "    \n",
    "date_sorter()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
